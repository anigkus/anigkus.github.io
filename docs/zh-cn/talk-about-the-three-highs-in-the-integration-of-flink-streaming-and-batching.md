<script>
var pageHeader=document.getElementsByClassName("page-header")[0].innerHTML;
 pageHeader="<center><img style='border-radius: 50% !important;' src='https://avatars.githubusercontent.com/u/88264073?s=400&amp;u=63e618520a5b6aa87636714e69f8228374c4e9b1&amp;v=4' width='200' height='200' alt='@anigkus' title='Github of Anigkus' ></center>"+pageHeader;
document.getElementsByClassName("page-header")[0].innerHTML=pageHeader;
</script>

<h1 style="color:#606c71;text-align:center;" >èŠèŠFlinkæµæ‰¹ä¸€ä½“ä¸­çš„"ä¸‰é«˜"</h1><br/>

[<h1 style="color:#606c71;text-align:center;" >Talk about the three highs in the integration of flink streaming and batching</h1><br/>]:#

<center>
<img src="../assets/images/talk-about-the-three-highs-in-the-integration-of-flink-streaming-and-batching/figure-1.jpg" alt="Talk about the three highs in the integration of flink streaming and batching" title="Github of Anigkus" >
</center>

[<center>]:#
[<img src="assets/images/talk-about-the-three-highs-in-the-integration-of-flink-streaming-and-batching/figure-1.jpg" alt="Talk about the three highs in the integration of flink streaming and batching" title="Github of Anigkus" >]:#
[</center>]:#

> <br/>&nbsp;&nbsp;&nbsp;&nbsp; æ­¤å¤„æ‰€è¯´çš„"ä¸‰é«˜"éå½¼"[ä¸‰é«˜](https://baike.baidu.com/item/ä¸‰é«˜/2898551)"(ğŸ˜‚)å“¦,è½¯ä»¶å‘å±•è¿­ä»£å†å²è¿‡ç¨‹ä¸­ä¸€ç›´æœ‰ä¸‰ä¸ªè¿½æ±‚ç›®æ ‡:é«˜æ€§èƒ½ã€é«˜å¹¶å‘ã€é«˜å¯ç”¨,ä¿—ç§°ä¸‰é«˜.ä¸‰è€…æ—¢æœ‰åŒºåˆ«ä¹Ÿæœ‰è”ç³»,ä»è½¯ä»¶å‘å±•å†å²æ¥çœ‹,æˆ‘ä¸ªäººè®¤ä¸ºçš„å‘å±•å†ç¨‹æ˜¯é«˜æ€§èƒ½(å•æ ¸)->é«˜å¹¶å‘(å¤šæ ¸)->é«˜å¯ç”¨(å¤šæœº).<br/>
> <br/>&nbsp;&nbsp;&nbsp;&nbsp; å½“ç„¶æ˜¯é¦–å…ˆé«˜æ€§èƒ½,ä»å¾ˆè€çš„DOSä¸ºå•ç”¨æˆ·æ“ä½œç³»ç»Ÿ,åˆ°åæ¥çš„Window98æ˜¯ä¸€ä¸ªå¤šä»»åŠ¡ç³»ç»Ÿ(å®é™…è¿˜æ˜¯å•è¿›ç¨‹),åœ¨åˆ°åæ¥UNIXæ”¯æŒå¤šç”¨æˆ·å¤šä»»åŠ¡æ“ä½œç³»ç»Ÿ(çœŸæ­£æ„ä¹‰çš„å¤šè¿›ç¨‹ã€å¤šçº¿ç¨‹ç³»ç»Ÿ),ç›®çš„éƒ½æ˜¯åœ¨ä¸€ä¸ªCPUçš„æƒ…å†µä¸‹æ€æ ·æœ€é«˜æ€§èƒ½çš„å¤„ç†ç¨‹åº.<br/>
> <br/>&nbsp;&nbsp;&nbsp;&nbsp; å…¶æ¬¡æ‰æ˜¯é«˜å¹¶å‘,éœ€è¦çªç ´çš„å½“ç„¶æ˜¯å•æœºå¤„ç†æé™.å•æœºå¦‚æœå†…å­˜æˆ–è€…CPUä¸è¶³,å¯ä»¥é€šè¿‡çºµå‘æ‰©å±•æ¥æé«˜å•ä¸ªæœºå™¨çš„ç¡¬ä»¶é…ç½®ä»è€Œè¾¾åˆ°å¹¶å‘çš„æœ€å¤§åŒ–,å•æ ¸å˜å¤šæ ¸,è¿™æ ·å°±èƒ½åŒæ—¶å¹¶è¡Œå¤šä¸ªä»»åŠ¡,ä»è€ŒåŠ é€Ÿå¤„ç†çš„æ€»æ—¶é—´æˆæœ¬.<br/>
> <br/>&nbsp;&nbsp;&nbsp;&nbsp; é‚£ä¹ˆå½“å•æœºå¤„ç†çš„æ€§èƒ½è¾¾åˆ°ä¸€å®šçš„ç“¶é¢ˆçš„æ—¶å€™,è¿™æ—¶å€™å°±å¿…é¡»æ¨ªå‘æ‰©å±•,å°±æ˜¯å‘å±•åˆ†å¸ƒå¼,åˆ†å¸ƒå¼å°±æ¶‰åŠåˆ°é«˜å¯ç”¨,å°±æ˜¯å¿…é¡»è€ƒè™‘å•ä¸ªèŠ‚ç‚¹æŒ‚æ‰çš„å¯èƒ½æ€§,ä¸šç•Œé€šå¸¸çš„ä¸­é—´ä»¶éƒ¨ç½²3ä¸ªèŠ‚ç‚¹,ä¹Ÿå°±æ˜¯ä¸ºäº†é«˜å¯ç”¨è€Œè®¾è®¡çš„.<br/>
> <br/>

[> <br/>&nbsp;&nbsp;&nbsp;&nbsp; The "three highs" mentioned here are not "??three hights??(https://baike.baidu.com/item/ä¸‰é«˜/2898551)"(ğŸ˜‚) Oh,there have always been three pursuit goals in the iterative history of software development: high performance, high concurrency, and higt availability, commonly known as three hights. The there are both different and related. From the perspective of software development history, I personally think that the development process is high performance ( Single core) -> high concurrency (multi-core) -> high availability (multi-machine). ]:#
[> <br/>&nbsp;&nbsp;&nbsp;&nbsp; Of course, it is high performance first. From the very old DOS as as single-user operating system, to the later Window98 as a multi-tasking system (actually a single process), and later UNIX supports a multi-user multi-tasking operating system (the real meaning of multi-process, multi-threaded system),the purpose is how to process the program with the highest performance in the case of a CPU.]:#
[> <br/>&nbsp;&nbsp;&nbsp;&nbsp; The second is high concurrency. Of course, what needs to the broken is the processing limit of a single machine. If the memory of CPU of a single machine is insufficient, the hardware configuration os a single machine can be increased  by vertical expansion to maximize concurrency, and single-core becomes multi-core, so that parallelism can be achieved at the same time. Multiple tasks, thereby speeding up the overall thime cost of processing. ]:#
[> <br/>&nbsp;&nbsp;&nbsp;&nbsp; Then when the performance of the single-machine processing reaches a certain bottleneck, it must scale horizontally, that is, to develop and distributed involves high availability, that is, the possibility of a single node hanging up must be considered. The industry's usual middleware deployment 3 nodes, which is designed for high availability.  ]:#
[> <br/>]:#

<center>
<img src="../assets/images/talk-about-the-three-highs-in-the-integration-of-flink-streaming-and-batching/figure-2.png" alt="Talk about the three highs in the integration of flink streaming and batching" title="Github of Anigkus" >
FlinkåŸºæœ¬æ¶æ„å’Œæ‰§è¡Œæµç¨‹
</center>

[Flink architecture and process]:#

Flinkä¸­æ‰€æœ‰åˆ†å¸ƒå¼RPCé€šä¿¡éƒ½æ˜¯å€ŸåŠ©äº[Akkaæ¡†æ¶](https://doc.akka.io/docs/akka/current/general/terminology.html)(ä¸€æ¬¾é«˜æ€§èƒ½ã€é«˜å®¹é”™æ€§çš„åˆ†å¸ƒå¼å¹¶å‘åº”ç”¨æ¡†æ¶).
* Flink Programï¼šä½¿ç”¨CLIã€WebUIã€Code(Java&Scala) æäº¤ä»»åŠ¡ç­‰;
* Clientï¼šä½¿ç”¨DataStream(æµè®¡ç®—)ã€DataSet(æ‰¹è®¡ç®—)è¿›è¡Œä¸šåŠ¡é€»è¾‘å¼€å‘ç­‰;
* JobManagerï¼šè´Ÿè´£æ˜¯èµ„æºçš„åˆ†é…ã€CheckPointçš„åè°ƒã€ä»»åŠ¡çŠ¶æ€ç»´æŠ¤ç­‰(<font color="red">JobManager Standbyéœ€è¦å€ŸåŠ©Zookeeperæˆ–è€…Yarnæ¥å®ç°</font>);
* TaskManagerï¼šç›¸å½“äºSlave,è´Ÿè´£å…·ä½“çš„ä»»åŠ¡æ‰§è¡Œå’Œä»¥åŠå¯¹åº”ä»»åŠ¡åœ¨æ¯ä¸ªèŠ‚ç‚¹çš„èµ„æºç”³è¯·å’Œç®¡ç†ç­‰;

[All distributed RPC communication in Flink relies on the ??Akka framework??(https://doc.akka.io/docs/akka/current/general/terminology.html) (a high-performance, fault-tolerant distributed Concurrent Application Framework).]:#
[* Flink Program: Submit tasks using CLI, WebUI, Code(Java&Scala), etc.;]:#
[* Client: Use DataStream (stream computing), DataSet (batch computing) for business logic development, etc.;]:#
[* JobManager: Responsible for resource allocation, CheckPoint coordination, task stats maintenance, etc. (<font color="red">JobManager Standby needs to be implemented with Zookeeper or Yarn</font>); ]:#
[* TaskManager: equivalent to Slave, responsible for specific task execution and resource application and management of corresponding tasks in echo node, etc.]:#


# é«˜æ€§èƒ½

[# High Performance]:#

## Flinkç¼“å­˜æœºåˆ¶

[## Flink Cache Mechanism]:#

### åˆ†å¸ƒå¼ç¼“å­˜

[### Distributed Cache]:#

&nbsp;&nbsp;&nbsp;&nbsp; åœ¨æ‰¹è®¡ç®—ä¸­,éœ€è¦å¤„ç†çš„æ•°æ®å¤§éƒ¨åˆ†æ¥è‡ªå¤–éƒ¨æ–‡ä»¶,è¿™äº›æ–‡ä»¶å¯èƒ½æ¥è‡ªç±»ä¼¼äºHDFSç³»ç»Ÿ,ä¹Ÿå¯ä»¥æ˜¯ç±»ä¼¼äºAWSä¸­S3æ–‡ä»¶ç³»ç»Ÿä¸­,ä½†æ˜¯Flinkå¹¶ä¸åƒMapReduceä¸€æ ·å¯ä»¥è®©è®¡ç®—éšç€æ•°æ®æ‰€åœ¨çš„ä½ç½®ä¸Šè€Œè¿›è¡Œ,å› æ­¤å¤šæ•°æƒ…å†µä¸‹ä¼šå‡ºç°ç½‘ç»œé¢‘ç¹åœ°å¤åˆ¶æ–‡ä»¶çš„æƒ…å†µ.å› æ­¤å¯¹äºæœ‰äº›é«˜é¢‘ä½¿ç”¨çš„æ–‡ä»¶å¯ä»¥é€šè¿‡ä½¿ç”¨Flinkå†…éƒ¨æä¾›çš„ä¸€ç§åˆ†å¸ƒå¼ç¼“å­˜æœºåˆ¶,å°†å…¶æ”¾ç½®åœ¨æ¯å°è®¡ç®—èŠ‚ç‚¹å®ä¾‹çš„æœ¬åœ°å†…å­˜ä¸­,å¯ä»¥ä½¿ç”¨æˆ·åœ¨å¹¶è¡Œå‡½æ•°ä¸­å¾ˆæ–¹ä¾¿çš„è¯»å–æœ¬åœ°æ–‡ä»¶,å¹¶æŠŠå®ƒæ”¾åœ¨taskmanagerèŠ‚ç‚¹ä¸­,é˜²æ­¢taské‡å¤æ‹‰å–.æ­¤ç¼“å­˜çš„å·¥ä½œæœºåˆ¶æ˜¯ç¨‹åºæ³¨å†Œä¸€ä¸ªæ–‡ä»¶æˆ–è€…ç›®å½•(æœ¬åœ°æˆ–è€…è¿œç¨‹æ–‡ä»¶ç³»ç»Ÿï¼Œä¾‹å¦‚hdfsæˆ–è€…s3),é€šè¿‡ExecutionEnvironmentæ³¨å†Œç¼“å­˜æ–‡ä»¶å¹¶ä¸ºå®ƒèµ·ä¸€ä¸ªåç§°ã€‚ç„¶åå½“ç¨‹åºæ‰§è¡Œ,Flinkè‡ªåŠ¨å°†æ–‡ä»¶æˆ–è€…ç›®å½•å¤åˆ¶åˆ°æ‰€æœ‰taskmanagerèŠ‚ç‚¹çš„æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿ,ä»…ä¼šæ‰§è¡Œä¸€æ¬¡.ç”¨æˆ·å¯ä»¥é€šè¿‡è¿™ä¸ªæŒ‡å®šçš„åç§°æŸ¥æ‰¾æ–‡ä»¶æˆ–è€…ç›®å½•,ç„¶åä»taskmanagerèŠ‚ç‚¹çš„æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿè®¿é—®å®ƒ.å…¶å®åˆ†å¸ƒå¼ç¼“å­˜å°±ç›¸å½“äºæ¶ˆæ¯é˜Ÿåˆ—ä¸­çš„å¹¿æ’­æ¨¡å¼,æŠŠä¸€ä¸ªå˜é‡å¹¿æ’­åˆ°æ‰€æœ‰çš„taskmanagerä¸Š,åªä¸è¿‡è¿™é‡Œå¹¿æ’­çš„æ˜¯ä¸€ä¸ªæ–‡ä»¶.è¿™æ ·å°±èƒ½æœ‰æ•ˆçš„é¿å…å› ä¸ºè¯»å–æŸäº›æ–‡ä»¶è€Œå¿…é¡»é€šè¿‡è¿œç¨‹ç½‘ç»œè·å–æ–‡ä»¶å†…å®¹çš„æƒ…å†µ,è¿›è€Œæå‡æ•´ä¸ªä»»åŠ¡çš„æ‰§è¡Œæ•ˆç‡.

[&nbsp;&nbsp;&nbsp;&nbsp; In batch computing, most of the data to be processed comes from external files, which may come from systems like HDFS or S3 file systems in AWS, but Flink is not like MapReduce In the same way, the calculation can be performed with the location of the data, so in most cases, the network frequently copies files. Therefore, for some frequently used files, you can use a distributed cache mechanism provided  by Flink internally, Placing it in the local memory of each computing node instance allows users to easily read the local file in parallel functions, and put it in the taskmanager node to prevent tasks from being repeatedly pulled. The working mechanism of this cache is The program registers a file or directory (local or remote file system, such as hdfs or s3), registers the cache file with the ExecutionEnvironment and  gives it a name. Then when the program is executed, Flink automatically copies the file or directory to the local file system of all taskmanager nodes, which will only be executed once. Users can search for the file or directory by this specified name, and then access it from the local file system of the taskmanager node. In fact The distributed cache is equivalent to the broadcast mode in the message queue, which broadcasts a variable to all taskmanagers, except that a file is broadcast here. This can effectively avoid reading some files and having to obtain them through a remote network The situation of the file content, thereby improving the execution efficiency of the entire task. ]:#

### Network Buffer

&nbsp;&nbsp;&nbsp;&nbsp; Network Bufferå°±æ˜¯åœ¨ç½‘ç»œä¼ è¾“ä¸­ä½¿ç”¨åˆ°çš„ Buffer(å®é™…éç½‘ç»œä¼ è¾“ä¹Ÿä¼šç”¨åˆ°).äº†è§£ Flink ç½‘ç»œæ ˆçš„åŒå­¦åº”è¯¥ä¼šæ¯”è¾ƒæ¸…æ¥š,Flink ç»è¿‡ç½‘ç»œä¼ è¾“çš„ä¸Šä¸‹æ¸¸ Task çš„è®¾è®¡ä¼šæ¯”è¾ƒç±»ä¼¼ç”Ÿäº§è€…-æ¶ˆè´¹è€…æ¨¡å‹.å¦‚æœæ²¡æœ‰è¿™ä¸ªç¼“å†²åŒº,é‚£ä¹ˆç”Ÿäº§è€…æˆ–æ¶ˆè´¹è€…ä¼šæ¶ˆè€—å¤§é‡æ—¶é—´åœ¨ç­‰å¾…ä¸‹æ¸¸æ‹¿æ•°æ®å’Œä¸Šæ¸¸å‘æ•°æ®çš„ç¯èŠ‚ä¸Š.åŠ ä¸Šè¿™ä¸ªç¼“å†²åŒº,ç”Ÿäº§è€…å’Œæ¶ˆè´¹è€…è§£è€¦å¼€,ä»»ä½•ä¸€æ–¹çŸ­æ—¶é—´å†…çš„æŠ–åŠ¨ç†è®ºä¸Šå¯¹å¦ä¸€æ–¹çš„æ•°æ®å¤„ç†éƒ½ä¸ä¼šäº§ç”Ÿå¤ªå¤§å½±å“.


[&nbsp;&nbsp;&nbsp;&nbsp; Network Buffer is the Buffer used in network transmission (actually non-network transmission will also be used). Students who understand the Flink network stack should know better that Flink transmits the upstream and downstream tasks through the network. The design will be similar to the producer-consumer model. Without this buffer, the producer or consumer will spend a lot of time waiting for the downstream to get data and the upstream to send data. With this buffer, the producer and consumer In theory, the jitter of one party in a short time will not have much impact on the data processing of the other party.]:#

<center>
<img src="../assets/images/talk-about-the-three-highs-in-the-integration-of-flink-streaming-and-batching/figure-3.png" alt="Talk about the three highs in the integration of flink streaming and batching" title="Github of Anigkus" >
</center>
  
åœ¨ Flink ä¸­æœ‰ä¸‰ç§æƒ…å†µä¸‹ Netty æœåŠ¡å™¨å¯ä»¥æ¶ˆè´¹ç¼“å­˜ï¼š
* ç¼“å†²åŒºæ»¡ååˆ·æ–°
* ç¼“å†²åŒºè¶…æ—¶ååˆ·æ–°
* ç‰¹æ®Šäº‹ä»¶ååˆ·æ–°

[There are three situations in Flink where the Netty server can consume the cache:]:#
[* Refrsh when the buffer is full]:#
[* Refresh after buffer timeout]:#
[* Refresh after special events]:#

## Flinkåå‹æœºåˆ¶

[## Flink back pressure machanism ]:#

å…ˆè¯´ä¸€ä¸‹ä»€ä¹ˆæ˜¯åå‹,å¦‚ä¸‹å›¾:

[Let's about what back pressure is, as shown below:]:#

<center>
<img src="../assets/images/talk-about-the-three-highs-in-the-integration-of-flink-streaming-and-batching/figure-4.png" alt="Talk about the three highs in the integration of flink streaming and batching" title="Github of Anigkus" >
</center>

&nbsp;&nbsp;&nbsp;&nbsp; æ­£å¸¸æƒ…å†µä¸‹æ¶ˆæ¯å¤„ç†é€Ÿåº¦(Receiver)>=æ¶ˆæ¯çš„å‘é€é€Ÿåº¦(Sender),å°±ä¸ä¼šå‘é€æ¶ˆæ¯æ‹¥å µ.ç³»ç»Ÿè¿è¡Œæµç•…,ä½†æ˜¯å½“æ¶ˆæ¯å‘é€çš„å¤ªå¿«,æ¶ˆæ¯æ¥å—çš„å¤ªæ…¢,äº§ç”Ÿæ¶ˆæ¯æ‹¥å µ,å¦‚æœç³»ç»Ÿå¯ä»¥è‡ªåŠ¨é™ä½æ¶ˆæ¯å‘é€çš„é€Ÿåº¦,è¿™å°±æ˜¯åå‹æœºåˆ¶.

&nbsp;&nbsp;&nbsp;&nbsp;Flink å¦‚ä½•åœ¨ååé‡å’Œå»¶è¿Ÿä¹‹é—´åšæƒè¡¡å‘¢?åœ¨æµå¼å¤„ç†ç³»ç»Ÿä¸­,å¦‚æœå‡ºç°ä¸‹æ¸¸æ¶ˆè´¹çš„é€Ÿåº¦è·Ÿä¸ä¸Šä¸Šæ¸¸ç”Ÿäº§æ•°æ®çš„é€Ÿåº¦,å°±ç§ç°è±¡å°±å«åšåå‹.å‡ºç°åå‹æ—¶,ç†æ‰€åº”å½“é™åˆ¶ä¸Šæ¸¸ç”Ÿäº§è€…çš„é€Ÿåº¦,ä½¿å¾—ä¸‹æ¸¸çš„é€Ÿåº¦è·Ÿå¾—ä¸Šä¸Šæ¸¸çš„é€Ÿåº¦.åå‹ä¼šå¯¼è‡´æµå¤„ç†ä½œä¸šæ•°æ®å»¶è¿Ÿçš„å¢åŠ ,åŒæ—¶è¿˜ä¼šå½±å“åˆ°Checkpoint.Flink å¤©ç„¶æ”¯æŒæµå¼å¤„ç†,å³æ¯æ¥ä¸€æ¡æ•°æ®å°±èƒ½å¤„ç†ä¸€æ¡,è€Œä¸æ˜¯åƒ Spark Streaming ä¸€æ ·,å®Œå…¨æ˜¯å¾®æ‰¹å¤„ç†.ä½†æ˜¯ä¸ºäº†æé«˜ååé‡,é»˜è®¤ä½¿ç”¨çš„ Flink å¹¶ä¸æ˜¯æ¯æ¥ä¸€æ¡æ•°æ®å°±å¤„ç†ä¸€æ¡.é‚£è¿™ä¸ªåˆ°åº•æ˜¯æ€ä¹ˆæ§åˆ¶çš„å‘¢?Flink æ˜¯ä½¿ç”¨äº†é«˜æ•ˆæœ‰ç•Œçš„åˆ†å¸ƒå¼é˜»å¡é˜Ÿåˆ—.

[&nbsp;&nbsp;&nbsp;&nbsp; Under normal circumstances, if the message processing speed (Receiver) >= the message sending speed (Sender), there will be no message congestion. The system runs smoothly, but when the message is sent too fast, the message is received too slowly, resulting in message congestion. It can automatically reduce the speed of message sending, which is the back pressure mechanism.]:#

[&nbsp;&nbsp;&nbsp;&nbsp;How does Flink trade off between throughput and latency? In a streaming system, if the speed of downstream consumption cannot keep up with the speed of upstream production data, this phenomenon is called back pressure .When backpressure occurs, it is reasonable to limit the speed of upstream producers so that the downstream speed can keep up with the upstream speed. Backpressure will increase the data delay of stream processing jobs, and will also affect Checkpoint. Flink naturally supports streaming It can process one piece of data every time it comes, instead of a complete micro-batch like Spark Streaming. However, in order to improve throughput, the default Flink used does not process one piece of data every time. How to control it? Flink uses an efficient and bounded distributed blocking queue.]:#

<center>
<img src="../assets/images/talk-about-the-three-highs-in-the-integration-of-flink-streaming-and-batching/figure-5.png" alt="Talk about the three highs in the integration of flink streaming and batching" title="Github of Anigkus" >
</center>

&nbsp;&nbsp;&nbsp;&nbsp;ä¾‹å¦‚,ä¸Šæ¸¸ Subtask S2 å‘é€å®Œæ•°æ®åï¼Œè¿˜æœ‰ 4 ä¸ª Buffer è¢«ç§¯å‹,é‚£ä¹ˆä¼šæŠŠå‘é€æ•°æ®å’Œ Backlog size = 4 ä¸€å—å‘é€ç»™ä¸‹æ¸¸ Subtask S5,ä¸‹æ¸¸æ¥å—åˆ°æ•°æ®å,çŸ¥é“ä¸Šæ¸¸ç§¯å‹äº† 4 ä¸ªBuffer,äºæ˜¯å‘ Buffer Pool ç”³è¯· Buffer,ç”±äºå®¹é‡æœ‰é™,ä¸‹æ¸¸ InputChannel ç›®å‰ä»…æœ‰ 2 ä¸ª Buffer ç©ºé—´,æ‰€ä»¥,Subtask S6 ä¼šå‘ä¸Šæ¸¸ Subtask S2 åé¦ˆ Channel Credit = 2.ç„¶åä¸Šæ¸¸ä¸‹ä¸€æ¬¡æœ€å¤šåªç»™ä¸‹æ¸¸å‘é€ 2 ä¸ª Buffer çš„æ•°æ®,è¿™æ ·æ¯æ¬¡ä¸Šæ¸¸å‘é€çš„æ•°æ®éƒ½æ˜¯ä¸‹æ¸¸ InputChannel çš„ Buffer å¯ä»¥æ‰¿å—çš„æ•°æ®é‡,æ‰€ä»¥é€šè¿‡è¿™ç§åé¦ˆç­–ç•¥,ä¿è¯äº†ä¸ä¼šåœ¨å…±ç”¨çš„ Netty å’Œ TCP è¿™ä¸€å±‚æ•°æ®å †ç§¯è€Œå½±å“å…¶ä»– Subtask é€šä¿¡.

[&nbsp;&nbsp;&nbsp;&nbsp;For example, after the upstream Subtask S2 sends data, there are still 4 Buffers that are backlogged, then the sent data and Backlog size = 4 will be sent to the downstream Subtask S5. After receiving the data, the downstream knows There is a backlog of 4 Buffers in the upstream, so apply for Buffers from the Buffer Pool. Due to the limited capacity, the downstream InputChannel currently has only 2 Buffer spaces. Therefore, Subtask S6 will feedback Channel Credit = 2 to the upstream Subtask S2. Then the upstream will only give at most the next time. The data of 2 Buffers is sent downstream, so that the data sent upstream each time is the amount of data that the Buffer of the downstream InputChannel can bear. Therefore, through this feedback strategy, it is ensured that data will not accumulate in the shared Netty and TCP layers. Affects other Subtask communications.]:#

å¦‚ä½•å®šä½åå‹:

[How to locate back pressure:]:#

* [Monitoring Back Pressure](https://nightlies.apache.org/flink/flink-docs-release-1.14/docs/ops/monitoring/back_pressure/)
* [Monitoring, Metrics](https://flink.apache.org/2019/07/23/flink-network-stack-2.html)

## Flinkå†…å­˜ç®¡ç†

[## Flink Memory Management]:#

&nbsp;&nbsp;&nbsp;&nbsp;é’ˆå¯¹å†…å­˜ç®¡ç†,Flinkå®ç°çš„è‡ªèº«çš„ç‹¬ç«‹å†…å­˜æœºåˆ¶(å †å¤–å†…å­˜),è¿™æ ·çš„å¥½å¤„å°±æ˜¯å°½å¯èƒ½å‡å°‘JVM GCå¯¹ç³»ç»Ÿçš„å½±å“.Java ç”Ÿæ€åœˆæä¾›äº†ä¼—å¤šçš„åºåˆ—åŒ–æ¡†æ¶:Java serialization, Kryo, Apache Avro ç­‰ç­‰.ä½†æ˜¯ Flink å®ç°äº†è‡ªå·±çš„åºåˆ—åŒ–æ¡†æ¶,Flinké€šè¿‡åºåˆ—åŒ–å’Œååºåˆ—åŒ–å°†æ‰€æœ‰çš„æ•°æ®å¯¹è±¡è½¬æ¢æˆäºŒè¿›åˆ¶åœ¨å†…å­˜ä¸­å­˜å‚¨,é™ä½æ•°æ®å­˜å‚¨å¤§å°çš„åŒæ—¶,èƒ½å¤Ÿæ›´åŠ æœ‰æ•ˆåœ°å¯¹å†…å­˜ç©ºé—´è¿›è¡Œåˆ©ç”¨,é™ä½GCå¸¦æ¥çš„æ€§èƒ½ä¸‹é™æˆ–è€…ä»»åŠ¡ç‰¹æ®Šå¼‚å¸¸ç­‰é—®é¢˜,å› æ­¤Flinkè¾ƒä¸ºå…¶ä»–åˆ†å¸ƒå¼æ¡†æ¶å…±ç”¨JVMå†…å­˜ä¼šæ˜¾å¾—æ›´åŠ ç¨³å®š,ä¸ä¼šå› ä¸ºJVM GCç­‰é—®é¢˜è€Œå½±å“æ•´ä¸ªåº”ç”¨çš„è¿è¡ŒçŠ¶æ€.

[&nbsp;&nbsp;&nbsp;&nbsp;For memory management, Flink implements its own independent memory mechanism (out-of-heap memory), which has the advantage of minimizing the impact of JVM GC on the system. The Java ecosystem provides many serialization frameworks : Java serialization, Kryo, Apache Avro, etc. But Flink implements its own serialization framework. Flink converts all data objects into binary and stores them in memory through serialization and deserialization. While reducing the size of data storage, it can More effective use of memory space, reducing performance degradation or special task exceptions caused by GC, so Flink will be more stable than other distributed frameworks sharing JVM memory, and will not affect the entire application due to JVM GC and other problems. Operating status.]:# 

* å †å¤–å†…å­˜çš„å¥½å¤„:è¶…å¤§å†…å­˜çš„åˆ†é…ä¸å—GCå½±å“ã€å †å¤–å†…å­˜åœ¨å†™ç£ç›˜æˆ–ç½‘ç»œä¼ è¾“æ—¶æ˜¯ zero-copyã€å †å¤–å†…å­˜æ˜¯è¿›ç¨‹é—´å…±äº«;
* å †å¤–å†…å­˜çš„åå¤„:å†…å­˜ç®¡ç†æ›´åŠ å¤æ‚(éœ€è¦è‡ªå·±åˆ†é…å’Œé‡Šæ”¾)ã€åˆ†é…é€Ÿåº¦æ¯”å †å†…å†…å­˜è¦æ…¢ã€çŸ­ç”Ÿå‘½æœŸçš„å†…å­˜åˆ†é…æ•ˆç‡ä¸é«˜;


[* Benefits of off-heap memory: allocation of very large memory is not affected by GC, off-heap memory is zero-copy when writing to disk or network transmission, off-heap memory is shared between processes;]:#
[* Disadvantages of off-heap memory: memory management is more complicated (need to allocate and release by yourself), the allocation speed is slower than on-heap memory, and the efficiency of short-lived memory allocation is not high;]:#


# é«˜å¹¶å‘

[High Concurrency]:#

## Akkaæ¡†æ¶

[## Akka Framework]:#

&nbsp;&nbsp;&nbsp;&nbsp;å‰é¢æˆ‘ä»¬æåˆ°,Flinkä¸­æ‰€æœ‰åˆ†å¸ƒå¼RPCé€šä¿¡éƒ½æ˜¯å€ŸåŠ©äº[Akkaæ¡†æ¶](https://doc.akka.io/docs/akka/current/general/terminology.html),Flinkä»0.9ç‰ˆæœ¬é‡‡ç”¨çš„[Akkaåˆ†å¸ƒå¼é€šä¿¡](https://cwiki.apache.org/confluence/display/FLINK/Akka+and+actors)çš„å®ç°.æœ‰äº†Akka,æ‰€æœ‰çš„è¿œç¨‹è¿‡ç¨‹è°ƒç”¨(RPC)è¢«å®ç°æˆå¼‚æ­¥æ¶ˆæ¯.è¿™ä¸»è¦å½±å“äº†JobManagerã€TaskManagerå’ŒJobClientä¸‰ä¸ªç»„ä»¶.æœªæ¥,å¾ˆå¯èƒ½æ›´å¤šçš„ç»„ä»¶å°†è¢«è½¬æ¢æˆä¸€ä¸ªactor,ä½¿å®ƒä»¬å¯ä»¥å‘é€å’Œå¤„ç†å¼‚æ­¥æ¶ˆæ¯.

[&nbsp;&nbsp;&nbsp;&nbsp;As we mentioned earlier, all distributed RPC communication in Flink relies on the ??Akka framework??(https://doc.akka.io/docs/akka/current/general/terminology .html), the implementation of ??Akka distributed communication??(https://cwiki.apache.org/confluence/display/FLINK/Akka+and+actors) adopted by Flink from version 0.9. With Akka, all Remote Procedure Calls (RPC) are implemented as asynchronous messages. This mainly affects the three components JobManager, TaskManager and JobClient. In the future, it is likely that more components will be converted into an actor, allowing them to send and process asynchronous messages.]:#


&nbsp;&nbsp;&nbsp;&nbsp;Akkaä¸»è¦ç‰¹æ€§:
* é«˜å¹¶å‘ä¸åˆ†å¸ƒå¼:ä¸»è¦æ˜¯Akka Streams APIå®è¡Œ
* å¼¹æ€§è®¾è®¡å¯æ‰©å±•:åŸºäºAkka Clusteråº“å’ŒCluster Shardingæœºåˆ¶
* å®¹é”™æœºåˆ¶:Akka çš„å®¹é”™æœºåˆ¶æ˜¯åŸºäºå±‚æ¬¡ç»“æ„
* å»ä¸­å¿ƒåŒ–:æ²¡æœ‰å•ç‚¹æ•…éšœçš„åˆ†å¸ƒå¼ç³»ç»Ÿ,è‡ªåŠ¨è´Ÿè½½å’Œè·¨èŠ‚ç‚¹è‡ªé€‚åº”è·¯ç”±
* Actorsæ¨¡å‹:Actoræ¨¡å¼æ˜¯ä¸€ç§å¹¶å‘æ¨¡å‹,ä¸å¦ä¸€ç§æ¨¡å‹å…±äº«å†…å­˜å®Œå…¨ç›¸åï¼ŒActoræ¨¡å‹share nothing,è¿™ä¸ªæ¨¡å‹å‘å±•æœ‰äº›å¹´ä»£äº†,ç®€å•ç†è§£å°±æ˜¯æµæ°´çº¿,è¿™åœ¨æµå¼è®¡ç®—åœºæ™¯ä¸­éå¸¸é€‚åˆ.
* äº‹åŠ¡æ€§ Actors:åŸºäºCRDTä¿è¯æœ€ç»ˆä¸€è‡´æ€§
* æ”¯æŒ JAVA ä¸ Scala:åŒæ—¶æ”¯æŒè¿™ä¸¤ç§è¯­è¨€çš„APIåº“
* é«˜æ€§èƒ½:å•å°æœºå™¨ä¸Šé«˜è¾¾ 5000 ä¸‡æ¡æ¶ˆæ¯/ç§’ã€‚å†…å­˜å ç”¨å°ï¼›æ¯ GB å †çº¦ 250 ä¸‡ä¸ª actor

[&nbsp;&nbsp;&nbsp;&nbsp;Akka main features:]:#
[* High concurrency and distribution: mainly implemented by Akka Streams API.]:#
[* Elastic design is scalable: based on Akka Cluster library and Cluster Sharding mechanism.]:#
[* Fault tolerance: Akka's fault tolerance is based on a hierarchy.]:#
[* Decentralization: Distributed systems with no single point of failure, automatic load and adaptive routing across nodes.]:#
[* Actors model: Actor mode is a concurrency model, which is completely opposite to another model of sharing memory. Actor model shares nothing. This model has been developed for some years. Simple understanding is pipeline, which is very suitable in streaming computing scenarios. ]:#
[* Transactional Actors: Guaranteed eventual consistency based on CRDT.]:#
[* Supports JAVA and Scala: API library that supports both languages.]:#
[* High performance: up to 50 million messages/sec on a single machine. Small memory footprint; ~2.5M actors per GB heap.]:#

## ä½å»¶è¿Ÿ

[## Low Latency]:#

&nbsp;&nbsp;&nbsp;&nbsp; è¿™ä¸ªåŸºæœ¬ä¹Ÿæ˜¯åˆ©ç”¨æœ‰ç•Œçš„åˆ†å¸ƒå¼é˜»å¡é˜Ÿåˆ—,ä¹Ÿå°±æ˜¯åˆ©ç”¨åå‹æœºåˆ¶è€Œåšåˆ°ä½å»¶è¿Ÿå¹¶æé«˜å“åº”é€Ÿåº¦,ä»è€Œè¾¾åˆ°æé«˜å¹¶å‘æ•°;

[&nbsp;&nbsp;&nbsp;&nbsp; This basically also uses a bounded distributed blocking queue, that is, using a backpressure mechanism to achieve low latency and improve response speed, thereby increasing the number of concurrency;]:#

## Flinkå¹¶å‘æ‰§è¡Œ

[## Flink Concurrently Executes ]:#

&nbsp;&nbsp;&nbsp;&nbsp; è¯´åˆ°å¹¶å‘æ‰§è¡Œ,å°±ä¸å¾—ä¸è¯´Flinkä¸­çš„slotå’Œparallelism,æˆ‘ä»¬å…ˆæ¥äº†è§£ä¸‹slotå’Œparallelismçš„å…³ç³».

&nbsp;&nbsp;&nbsp;&nbsp; ä¸‹é¢å›¾ç‰‡ä¸­æœ‰ä¸¤ä¸ª Task Manager,æ¯ä¸ª Task Manager æœ‰2ä¸ª slot,è¿™æ ·æˆ‘ä»¬çš„ç®—å­æœ€å¤§å¹¶è¡Œåº¦é‚£ä¹ˆå°±å¯ä»¥è¾¾åˆ° 4 ä¸ª,åœ¨åŒä¸€ä¸ª slot é‡Œé¢å¯ä»¥æ‰§è¡Œ 1 è‡³å¤šä¸ªå­ä»»åŠ¡.

[&nbsp;&nbsp;&nbsp;&nbsp;When it comes to concurrent execution, we have to talk about slot and parallelism in Flink. Let's first understand the relationship between slot and parallelism]:#

[&nbsp;&nbsp;&nbsp;&nbsp; There are two Task Managers in the image below, each with 2 slots, so that the maximum parallelism of our operators can reach 4, and 1 to multiple subtasks can be executed in the same slot.]:#

<center>
<img src="../assets/images/talk-about-the-three-highs-in-the-integration-of-flink-streaming-and-batching/figure-6.png" alt="Talk about the three highs in the integration of flink streaming and batching" title="Github of Anigkus" >
</center>

### slotæ˜¯æŒ‡taskmanagerçš„å¹¶å‘æ‰§è¡Œèƒ½åŠ›
&nbsp;&nbsp;&nbsp;&nbsp;ä¸‹å›¾æ‰€ç¤º:taskmanager.numberOfTaskSlots:3;å³æ¯ä¸€ä¸ª taskmanager ä¸­çš„åˆ†é… 3 ä¸ª TaskSlot,4 ä¸ª taskmanager ä¸€å…±æœ‰ 12 ä¸ª TaskSlot.

[### slot refers to the concurrent execution capability of taskmanager]:#
[&nbsp;&nbsp;&nbsp;&nbsp;As shown in the figure below: taskmanager.numberOfTaskSlots:3; That is, each taskmanager is allocated 3 TaskSlots, and 4 taskmanagers have a total of 12 TaskSlots.]:#

<center>
<img src="../assets/images/talk-about-the-three-highs-in-the-integration-of-flink-streaming-and-batching/figure-7.png" alt="Talk about the three highs in the integration of flink streaming and batching" title="Github of Anigkus" >
</center>


### parallelismæ˜¯æŒ‡taskmanagerå®é™…ä½¿ç”¨çš„å¹¶å‘èƒ½åŠ›
&nbsp;&nbsp;&nbsp;&nbsp; ä¸‹å›¾æ‰€ç¤º:parallelism.default:1;å³è¿è¡Œç¨‹åºé»˜è®¤çš„å¹¶è¡Œåº¦ä¸º 1,12ä¸ª TaskSlot åªç”¨äº† 1 ä¸ª,æœ‰ 11 ä¸ªç©ºé—²,è®¾ç½®åˆé€‚çš„å¹¶è¡Œåº¦æ‰èƒ½æé«˜æ•ˆç‡.

[### parallelism refers to the concurrency capability actually used by taskmanager]:#
[&nbsp;&nbsp;&nbsp;&nbsp; As shown in the figure below: parallelism.default:1; That is, the default parallelism of the running program is 1, only 1 of the 12 TaskSlots are used, and 11 are idle. Setting the appropriate parallelism can improve efficiency.]:#

<center>
<img src="../assets/images/talk-about-the-three-highs-in-the-integration-of-flink-streaming-and-batching/figure-8.png" alt="Talk about the three highs in the integration of flink streaming and batching" title="Github of Anigkus" >
</center>

å¯ä»¥è¿™ä¹ˆç†è§£ä¸Šé¢ä¸¤ä¸ªæ¦‚å¿µ:
* slotå†³å®štaskmanageräº†æœ‰å¤šå°‘ä¸ªslot,æ¯ä¸ªä»»åŠ¡ä»£è¡¨åˆ†é…ç»™ä»»åŠ¡æ§½çš„ä¸€ç»„èµ„æº,slot åœ¨ Flink é‡Œé¢å¯ä»¥è®¤ä¸ºæ˜¯èµ„æºç»„,Flink å°†æ¯ä¸ªä»»åŠ¡åˆ†æˆå­ä»»åŠ¡å¹¶ä¸”å°†è¿™äº›å­ä»»åŠ¡åˆ†é…åˆ° slot æ¥å¹¶è¡Œæ‰§è¡Œç¨‹åº.
* parallelismå†³å®šäº†taskmanagerå¯ä»¥å¹¶è¡Œè¿è¡Œå¤šå°‘ä¸ª,å¯ä»¥ç†è§£ä¸ºå¹¶å‘çº¿ç¨‹æ•°æˆ–è€…å¹¶å‘ç®—å­æ•°.


æˆ‘ä»¬å°½å¯èƒ½åœ°ä¸ä»ç³»ç»Ÿä¸Šè®¾ç½®ï¼Œè€Œæ˜¯é’ˆå¯¹ä¸åŒçš„ä»»åŠ¡ï¼Œè‡ªå·±å†…éƒ¨è®¾ç½®ã€‚æ‰€ä»¥è®¾ç½®parallelismçš„é˜²èŒƒä¼˜å…ˆçº§æ˜¯ï¼š
ç®—å­(operator)çº§åˆ« > è¿è¡Œç¯å¢ƒçº§åˆ« > å®¢æˆ·ç«¯çº§åˆ« > ç³»ç»Ÿçº§åˆ«


[The above two concepts can be understood as follows:]:#
[* Slot determines how many slots the taskmanager has. Each task represents a set of resources allocated to the task slot. A slot can be considered as a resource group in Flink. Flink divides each task into subtasks and assigns these subtasks to slots. Execute programs in parallel.]:#
[* Parallelism determines how many taskmanager can run in parallel, which can be understood as the number of concurrent threads or the number of concurrent operators.]:#


[We try not to set it from the system as much as possible, but to set it internally for different tasks. So the precautionary priority for setting parallelism is:]:#
[Operator level > Runtime environment level > Client level > System level]:#


# é«˜å¯ç”¨
[# High Availability]:#

## JobManageré«˜å¯ç”¨
&nbsp;&nbsp;&nbsp;&nbsp; ç›®å‰Flinké«˜å¯ç”¨å¯ä»¥æ”¯æŒStandalone Clusterå’ŒYarn Clusterä¸¤ç§é›†ç¾¤æ¨¡å¼,åŒæ—¶Flinké«˜å¯ç”¨ä¸»è¦é’ˆå¯¹çš„æ˜¯JobManager,å› ä¸ºJobManageræ˜¯æ•´ä¸ªé›†ç¾¤çš„ç®¡ç†èŠ‚ç‚¹,è´Ÿè´£æ•´ä¸ªé›†ç¾¤çš„ä»»åŠ¡è°ƒåº¦ã€ä»»åŠ¡åˆ†é…ã€èµ„æºç®¡ç†ç­‰,å¦‚æœJobManagerå‡ºç°é—®é¢˜é‚£ä¹ˆå°†ä¼šå¯¼è‡´æ–°çš„Jobæ— æ³•æäº¤,å¹¶ä¸”å·²ç»å­˜åœ¨çš„Jobä¹Ÿä¼šå…¨éƒ¨å¤±è´¥,å› æ­¤å¯¹JobManagerçš„é«˜å¯ç”¨ä¿è¯å°±æ˜¾å¾—å°¤ä¸ºé‡è¦,Flinké»˜è®¤æ˜¯ä¸å¼€å¯JobManageré«˜å¯ç”¨é…ç½®çš„,(<font color="green">ç•™ä¸ªå°é—®é¢˜,å¦‚æœæ˜¯Kuberneteså‘¢!)</font>.

### Standalone Cluster
&nbsp;&nbsp;&nbsp;&nbsp; Flinkåœ¨Standaloneé›†ç¾¤ä¸­é«˜å¯ç”¨ä¸»è¦æ˜¯å€ŸåŠ©Zookeeperæ¥å®ç°çš„,å¹¶ä¸”è¿˜éœ€è¦ä¸€ä¸ªæ–‡ä»¶ç³»ç»Ÿ,å¦‚hdfsç­‰(ç”¨æ¥å­˜å‚¨JobManagerçš„å…ƒæ•°æ®).JobManagerçš„æœåŠ¡ä¿¡æ¯ä¼šè¢«æ³¨å†Œåˆ°Zookeeperä¸­,å¹¶é€šè¿‡[Zookeeper](https://nightlies.apache.org/flink/flink-docs-master/docs/deployment/ha/zookeeper_ha/)å®ŒæˆJobManager Leaderçš„é€‰ä¸¾.Standaloneé›†ç¾¤ä¼šåŒæ—¶å­˜åœ¨å¤šä¸ªJobManager,ä½†æ˜¯åªæœ‰ä¸€ä¸ªæä¾›æœåŠ¡,å…¶ä»–å¤„äºStandbyçŠ¶æ€,å½“Active JobManagerå¤±å»è¿æ¥å(èŠ‚ç‚¹æ¶ˆå¤±æˆ–è€…ç½‘ç»œè¶…æ—¶ç­‰),Zookeeperä¼šè‡ªåŠ¨ä»å…¶ä»–Standbyåˆ—è¡¨ä¸­é€‰ä¸¾ä¸€ä¸ªæ–°çš„JobManageræ¥æ¥ç®¡Flinké›†ç¾¤å¹¶æä¾›æœåŠ¡.


[## JobManager high availability]:#
[&nbsp;&nbsp;&nbsp;&nbsp; Currently Flink high availability can support Standalone Cluster and Yarn Cluster two cluster modes, and Flink high availability is mainly aimed at JobManager, because JobManager is the management node of the entire cluster, responsible for task scheduling, Task allocation, resource management, etc. If there is a problem with the JobManager, the new job will not be submitted, and the existing jobs will all fail. Therefore, the high availability guarantee of the JobManager is particularly important. Flink does not enable the JobManager high availability by default. Configurable, (<font color="green">Leave a small question, what about Kubernetes!)</font>.]:#

[### Standalone Cluster]:#
[&nbsp;&nbsp;&nbsp;&nbsp; In Zookeeper, and through ??Zookeepe??(https://nightlies.apache.org/flink/flink-docs-master/docs/deployment/ha/zookeeper_ha/) to complete the election of the JobManager Leader. There will be multiple JobManagers in the Standalone cluster at the same time , but only one provides services, and the others are in the Standby state. When the Active JobManager loses connection (node â€‹â€‹disappears or network timeout, etc.), Zookeeper will automatically elect a new JobManager from the other Standby lists to take over the Flink cluster and provide services.]:#


<center>
<img src="../assets/images/talk-about-the-three-highs-in-the-integration-of-flink-streaming-and-batching/figure-9.png" alt="Talk about the three highs in the integration of flink streaming and batching" title="Github of Anigkus" >
</center>


### Yarn Cluster

&nbsp;&nbsp;&nbsp;&nbsp; Flink Yarn Sessioné›†ç¾¤æ¨¡å¼çš„é«˜å¯ç”¨æ˜¯ä¾èµ–YarnååŠ©è¿›è¡Œ,ä¸»è¦å› ä¸ºæ˜¯Yarnæœ¬èº«å¯¹è¿è¡Œåœ¨å…¶ä¸Šé¢çš„çš„åº”ç”¨å…·æœ‰ä¸€å®šçš„å®¹é”™ä¿è¯.Flink On Yarn çš„æ¨¡å¼å…¶å®å°±æ˜¯å°†Flink JobManageræ‰§è¡Œåœ¨ApplicationMasteræ‰€åœ¨çš„å®¹å™¨ä¸­,åŒæ—¶Yarnä¹Ÿä¸ä¼šå¯åŠ¨å¤šä¸ªJobManager(å’Œzookeeperæœºåˆ¶æœ‰ç‚¹ç›¸ä¼¼),ä½†æ˜¯ä¸æ˜¯é€šè¿‡zookeeeperé€‰ä¸¾æ¥å†³å®šé‚£ä¸ªStandbyæˆä¸ºLeader,è€Œæ˜¯é€šè¿‡é‡å¯çš„æ–¹å¼ä¿è¯JobManagerçš„é«˜å¯ç”¨.

[### Yarn Cluster]:#

[&nbsp;&nbsp;&nbsp;&nbsp; The high availability of the Flink Yarn Session cluster mode relies on the assistance of Yarn, mainly because Yarn itself has a certain fault tolerance guarantee for the applications running on it. The Flink On Yarn mode is actually a The JobManager is executed in the container where the ApplicationMaster is located, and Yarn will not start multiple JobManagers (similar to the zookeeper mechanism), but it does not decide which Standby becomes the Leader through zookeeper election, but ensures the high availability of the JobManager by restarting.]:#

## Checkpointså’ŒSavepointsæœºåˆ¶

&nbsp;&nbsp;&nbsp;&nbsp; æˆ‘ä»¬éƒ½çŸ¥é“å‡ºäº†ç‹¬ç«‹çš„ç»„ä»¶éœ€è¦é«˜å¯ç”¨å¤–,taskä¹Ÿéœ€è¦é«˜å¯ç”¨,æ¯”å¦‚å¼‚å¸¸æƒ…å†µæˆ–è€…æœºå™¨æ‰©å®¹å‡çº§ç­‰æƒ…å†µ,è¿™ä¸ªæ—¶å€™å°±éœ€è¦ç³»ç»Ÿæä¾›ä¸€äº›æœºåˆ¶æ¥ä¿è¯å½“å‰æ­£åœ¨è¿è¡Œçš„taskçš„è®¡ç®—çŠ¶æ€èƒ½å¤Ÿåšåˆ°è¯­ä¹‰ä¿è¯æˆ–è€…è¯´ç±»ä¼¼çš„äº‹åŠ¡ä¿è¯æœºåˆ¶,Flinkå¯¹äºtaskæä¾›2ç§æ–¹å¼,ä¸€ç§æ˜¯è‡ªåŠ¨(Checkpoints)å’Œæ‰‹åŠ¨(Savepoints).[Savepoint different from a Checkpoint?](https://nightlies.apache.org/flink/flink-docs-master/docs/ops/state/savepoints/).

[## Checkpoints and Savepoints mechanism]:#

[&nbsp;&nbsp;&nbsp;&nbsp; We all know that independent components need high availability, and tasks also need high availability, such as abnormal situations or machine expansion and upgrades. The computing state of the task can achieve semantic guarantee or a similar transaction guarantee mechanism. Flink provides two methods for tasks, one is automatic (Checkpoints) and manual (Savepoints). ??Savepoint different from a Checkpoint???(https: //nightlies.apache.org/flink/flink-docs-master/docs/ops/state/savepoints/).]:#



&nbsp;&nbsp;&nbsp;&nbsp; [Checkpoints](https://nightlies.apache.org/flink/flink-docs-master/docs/ops/state/checkpoints/)æ˜¯ä¿å­˜ç‚¹çš„æ„æ€,å°±æ˜¯è¯´Flinkä¼šåœ¨è¾“å…¥çš„æ•°æ®é›†ä¸Šæˆ–è€…è¯´è¿‡ç¨‹ä¸­é—´éš”æ€§çš„ç”ŸæˆCheckout barrier(åˆ†ç•Œç‚¹),é€šè¿‡barrieræŠŠé—´éš”æ—¶é—´å†…çš„æ•°æ®åˆ†åˆ°å¯¹åº”çš„ä¿å­˜ç‚¹ä¸­,è¿™æ ·å½“åº”ç”¨å‡ºç°å¼‚å¸¸æƒ…å†µæ—¶,å°±èƒ½å¤Ÿä»ä¸Šæ¬¡çš„å¿«ç…§ä¸­ä¸­æ¢å¤taskä¹‹å‰çš„çŠ¶æ€,ä½†æ˜¯å½“å‰çŠ¶æ€çš„ç©ºé—´å¤§å°å’Œåº”ç”¨æœ‰ç›´æ¥å…³ç³»,å¦‚æœå½“å‰è®¡ç®—çš„ä»»åŠ¡å¾ˆå¤§,é‚£ä¹ˆä¿å­˜çš„æ—¶é—´å°±ä¼šå¾ˆé•¿,å¹¶ä¸”ä¹Ÿä¼šå½±å“ååé‡.checkoutçš„ä¿å­˜ç‚¹çš„æ”¯æŒMemoryã€FileSystemã€RocksDB,ä½†æ˜¯æ•°æ®é€šå¸¸ä¿å­˜åœ¨JobManagerèŠ‚ç‚¹ä¸Šæˆ–è€…HDFSä¸Š,æ€§èƒ½å·®å¼‚Memory>FileSystem>RocksDB(æ€§èƒ½æœ€å·®),æ”¯æŒä¸‰ç§è®¾ç½®(å…¨å±€ã€ä»»åŠ¡ã€å®ä¾‹)çº§åˆ«.

[&nbsp;&nbsp;&nbsp;&nbsp; ??Checkpoints??(https://nightlies.apache.org/flink/flink-docs-master/docs/ops/state/checkpoints/) means save points, which means that Flink will Checkout barriers (demarcation points) are generated at intervals on the input data set or in the process, and the data in the interval time is divided into corresponding save points through the barrier, so that when an abnormal situation occurs in the application, it can start from the last time. The state before the task is restored in the snapshot, but the space size of the current state is directly related to the application. If the current computing task is large, the saving time will be very long, and it will also affect the throughput. Supports Memory, FileSystem, RocksDB, but the data is usually stored on the JobManager node or HDFS, the performance difference is Memory>FileSystem>RocksDB (the worst performance), and three settings (global, task, instance) levels are supported.]:#

å¦‚å›¾æ‰€ç¤º,æ€»å…±æœ‰4ä¸ªä¿å­˜ç‚¹:
* ç¬¬ä¸€ä¸ªCheckpointä¿å­˜1ä¸ªEvent
* ç¬¬äºŒä¸ªCheckpointä¿å­˜3ä¸ªEvent
* ç¬¬ä¸‰ä¸ªCheckpointä¿å­˜6ä¸ªEvent
* ç¬¬å››ä¸ªCheckpointä¿å­˜4ä¸ªEvent

æ–°çš„æ•°æ®å› ä¸ºæ—¶é—´è¿˜æ²¡åˆ°å› æ­¤æš‚æ—¶ä¸ä¼šè§¦å‘å®šæ—¶ä»»åŠ¡å»ä¿å­˜Checkpoint.

[As shown, there are a total of 4 savepoints:]:#
[* The first Checkpoint saves 1 Event]:#
[* The second Checkpoint saves 3 Events]:#
[* The third Checkpoint saves 6 Events]:#
[* The fourth Checkpoint saves 4 Events]:#

[The new data will not trigger the scheduled task to save the Checkpoint because the time has not yet come.]:#


<center>
<img src="../assets/images/talk-about-the-three-highs-in-the-integration-of-flink-streaming-and-batching/figure-10.png" alt="Talk about the three highs in the integration of flink streaming and batchingâ€" title="Github of Anigkus" >
Checkpointæœºåˆ¶
</center>

[Checkpoint mechanism]:#

&nbsp;&nbsp;&nbsp;&nbsp;[Savepoints](https://nightlies.apache.org/flink/flink-docs-master/docs/ops/state/savepoints/)å…¶å®å°±æ˜¯æ£€æŸ¥ç‚¹çš„ä¸€ç§ç‰¹æ®Šå®ç°,åº•å±‚è¿˜æ˜¯ä½¿ç”¨Checkpointsæœºåˆ¶,åªä¸è¿‡Savepointsæ˜¯ç”¨æˆ·ä»¥æ‰‹åŠ¨çš„æ–¹å¼è§¦å‘,å¹¶å°†æ•°æ®æŒä¹…åŒ–åˆ°æŒ‡å®šçš„å­˜å‚¨è·¯å¾„,ä¸»è¦ç›®çš„æ˜¯ç³»ç»Ÿå‡çº§æˆ–è€…é›†ç¾¤ç»´æŠ¤è¿‡ç¨‹ä¸­çš„çŠ¶æ€æ•°æ®,é¿å…å› ä¸ºåœæœºè¿ç»´æˆ–è€…æ­£å¸¸ç»ˆæ­¢ç­‰æ“ä½œè€Œå¯¼è‡´ç³»ç»Ÿæ— æ³•æ¢å¤åˆ°åŸæœ‰çš„è®¡ç®—çŠ¶æ€çš„æƒ…å†µ.

[&nbsp;&nbsp;&nbsp;&nbsp; ??Savepoints??(https://nightlies.apache.org/flink/flink-docs-master/docs/ops/state/savepoints/) is actually a special implementation of checkpoints. The Checkpoints mechanism is still used, except that Savepoints are manually triggered by the user and persist the data to the specified storage path. The main purpose is the status data in the process of system upgrade or cluster maintenance, avoiding operation and maintenance due to downtime or normal termination, etc. The system cannot be restored to the original computing state due to the operation.]:#

# ç»“è®º

&nbsp;&nbsp;&nbsp;&nbsp;æœ¬æ–‡ä¸»è¦åˆ†æäº†å’Œè®¨è®ºFlinkåœ¨æµå¼è®¡ç®—çš„ä¸€äº›æŠ€æœ¯å’Œæœºåˆ¶,Flinkæ˜¯ç›®å‰å¼€æºç¤¾åŒºä¸­å”¯ä¸€ä¸€å¥—é›†é«˜ååã€ä½å»¶è¿Ÿã€é«˜æ€§èƒ½ä¸‰è€…äºä¸€èº«çš„åˆ†å¸ƒå¼æµå¼æ•°æ®å¤„ç†æ¡†æ¶.åƒApache Sparkä¹Ÿåªèƒ½å…¼é¡¾é«˜ååå’Œé«˜æ€§èƒ½ç‰¹æ€§,ä¸»è¦å› ä¸ºåœ¨Spark Streamingæµå¼è®¡ç®—ä¸­æ— æ³•åšåˆ°ä½å»¶è¿Ÿä¿éšœ(å› ä¸ºSpark Streaming å¯¹ä½å»¶è¿Ÿæ”¯æŒä¸è¶³);è€Œæµå¼è®¡ç®—æ¡†æ¶Apache Stormåªèƒ½æ”¯æŒä½å»¶è¿Ÿå’Œé«˜æ€§èƒ½ç‰¹æ€§,ä½†æ˜¯æ— æ³•æ»¡è¶³é«˜åå(æ¡†æ¶æœ¬èº«å’Œè¯­ä¹‰é€»è¾‘)çš„è¦æ±‚;è€Œæ»¡è¶³é«˜ååã€ä½å»¶è¿Ÿã€é«˜æ€§èƒ½è¿™ä¸‰ä¸ªç›®æ ‡å¯¹åˆ†å¸ƒå¼æµå¼è®¡ç®—æ¡†æ¶æ¥è¯´æ˜¯éå¸¸é‡è¦.

[# Conclusion]:#

[&nbsp;&nbsp;&nbsp;&nbsp;This article mainly analyzes and discusses some technologies and mechanisms of Flink in stream computing. Flink is the only set of distribution in the open source community that integrates high throughput, low latency and high performance Streaming data processing framework. Like Apache Spark, it can only take into account the characteristics of high throughput and high performance, mainly because there is no guarantee of low latency in Spark Streaming stream computing (because Spark Streaming does not support low latency); while streaming The computing framework Apache Storm can only support low-latency and high-performance features, but it cannot meet the requirements of high throughput (the framework itself and semantic logic); while satisfying the three goals of high throughput, low latency, and high performance is critical to the distributed stream computing framework is very important.]:#

<br>

### [back](./)
